{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. è¯»å–ç›®æ ‡å˜é‡\n",
    "target = pd.read_csv(\"year6_obesity_cleaned.csv\")\n",
    "\n",
    "# 2. è¯»å–å‹åŠ›ä»£ç†å˜é‡\n",
    "overcrowding = pd.read_csv(\"overcrowding_cleaned.csv\")\n",
    "lone_parent = pd.read_csv(\"cleaned_lone.csv\")\n",
    "commute = pd.read_csv(\"commute_cleaned.csv\")\n",
    "social_housing = pd.read_csv(\"social_housing_cleaned.csv\")\n",
    "\n",
    "# 3. è¯»å–æ§åˆ¶å˜é‡\n",
    "unemployment = pd.read_csv(\"unemployment_inactive_cleaned.csv\")\n",
    "nonwhite = pd.read_csv(\"nonwhite_cleaned.csv\")\n",
    "education = pd.read_csv(\"higher_edu_cleaned.csv\")\n",
    "household_size = pd.read_csv(\"household_size_cleaned.csv\")\n",
    "age_10_11 = pd.read_csv(\"age_10_11_cleaned.csv\")\n",
    "\n",
    "# 4. ç»Ÿä¸€ä¸»é”®åï¼ˆå‡è®¾æ‰€æœ‰æ–‡ä»¶ç¬¬1åˆ—æ˜¯ MSOA ç¼–ç ï¼‰\n",
    "for df in [target, overcrowding, lone_parent, commute, social_housing,\n",
    "           unemployment, nonwhite, education, household_size, age_10_11]:\n",
    "    df.rename(columns={df.columns[0]: \"MSOA_code\"}, inplace=True)\n",
    "\n",
    "# 5. åˆå¹¶æ‰€æœ‰è¡¨æ ¼ï¼ˆå·¦è¿æ¥ï¼‰\n",
    "merged = target \\\n",
    "    .merge(overcrowding, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(lone_parent, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(commute, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(social_housing, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(unemployment, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(nonwhite, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(education, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(household_size, on=\"MSOA_code\", how=\"left\") \\\n",
    "    .merge(age_10_11, on=\"MSOA_code\", how=\"left\")\n",
    "\n",
    "# 6. æ£€æŸ¥åˆå¹¶åçš„æ•°æ®æƒ…å†µ\n",
    "print(\"åˆå¹¶åæ•°æ®ç»´åº¦ï¼š\", merged.shape)\n",
    "print(\"\\nç¼ºå¤±å€¼æ£€æŸ¥ï¼š\")\n",
    "print(merged.isnull().sum())\n",
    "\n",
    "# 7. ä¿å­˜åˆå¹¶ç»“æœ\n",
    "merged.to_csv(\"Merged_MSOA_Data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡ºæ‰€æœ‰æœ‰ç¼ºå¤±å€¼çš„è¡Œ\n",
    "missing_rows = merged[merged.isnull().any(axis=1)]\n",
    "\n",
    "# æŸ¥çœ‹ç¼ºå¤±è¡Œçš„æ•°é‡å’Œå‰å‡ è¡Œå†…å®¹\n",
    "print(f\"æœ‰ç¼ºå¤±å€¼çš„ MSOA æ€»æ•°ï¼š{missing_rows.shape[0]}\")\n",
    "missing_rows.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ\n",
    "merged_clean = merged.dropna()\n",
    "print(\"æ¸…æ´—åæ•°æ®ç»´åº¦ï¼š\", merged_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æè¿°ç»Ÿè®¡\n",
    "merged_clean.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"å˜é‡åˆ—è¡¨ï¼š\")\n",
    "print(merged_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# é€‰å‡ ä¸ªå˜é‡ç”»å›¾ï¼ˆå¯æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰\n",
    "cols_to_plot = [\n",
    "    \"obesity_rate\", \"overcrowded_percent\", \"lone_parent_percent\",\n",
    "    \"long_commute_percent\", \"social_housing_percent\"\n",
    "]\n",
    "\n",
    "# å¤šå˜é‡åˆ†å¸ƒå›¾\n",
    "for col in cols_to_plot:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.histplot(merged_clean[col], kde=True, bins=30)\n",
    "    plt.title(f\"{col} åˆ†å¸ƒå›¾\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‹åŠ›ä»£ç†å˜é‡ç›¸å…³æ€§çŸ©é˜µ\n",
    "stress_vars = [\n",
    "    \"overcrowded_percent\", \"lone_parent_percent\",\n",
    "    \"long_commute_percent\", \"social_housing_percent\"\n",
    "]\n",
    "\n",
    "print(\"å‹åŠ›ä»£ç†å˜é‡çš„ç›¸å…³æ€§çŸ©é˜µï¼š\")\n",
    "print(merged_clean[stress_vars].corr())\n",
    "\n",
    "# çƒ­åŠ›å›¾æ˜¾ç¤º\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(merged_clean[stress_vars].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"å‹åŠ›ä»£ç†å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£é‡Šè·³è¿‡PCAçš„åŸå› ï¼Œç°åœ¨è¿›è¡Œç¬¬ä¸‰é˜¶æ®µçš„å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb68ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 1. è®¾ç½®è‡ªå˜é‡ï¼ˆæ§åˆ¶å˜é‡ + å‹åŠ›ä»£ç†å˜é‡ï¼‰\n",
    "features = [\n",
    "    \"percent_age_10_11\", \"higher_education_percent\", \"average_household_size\",\n",
    "    \"unemployment_rate\", \"inactive_rate\", \"nonwhite_percent\",\n",
    "    \"overcrowded_percent\", \"lone_parent_percent\", \"long_commute_percent\", \"social_housing_percent\"\n",
    "]\n",
    "\n",
    "# åœ¨å»ºæ¨¡å‰è®¾ç½® MSOA ç¼–ç ä¸º indexï¼ˆå‡è®¾ merged_clean é‡Œæœ‰ MSOA ç¼–ç å­—æ®µï¼‰\n",
    "X = merged_clean[features]\n",
    "X.index = merged_clean[\"MSOA_code\"]  # âœ… æŠŠç¼–ç è®¾ç½®æˆ index\n",
    "\n",
    "y = merged_clean[\"obesity_rate\"]\n",
    "y.index = merged_clean[\"MSOA_code\"]  # âœ… åŒæ­¥ y çš„ index\n",
    "\n",
    "# 3. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆ75%:25%ï¼‰\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 4. å»ºç«‹çº¿æ€§å›å½’æ¨¡å‹\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# 5. å»ºç«‹éšæœºæ£®æ—æ¨¡å‹\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# 6. è¯„ä¼°æ¨¡å‹è¡¨ç°\n",
    "print(\"ğŸ¯ çº¿æ€§å›å½’ R2ï¼š\", round(r2_score(y_test, y_pred_lr), 3))\n",
    "print(\"ğŸ¯ çº¿æ€§å›å½’ RMSEï¼š\", round(np.sqrt(mean_squared_error(y_test, y_pred_lr)), 3))\n",
    "\n",
    "print(\"ğŸŒ² éšæœºæ£®æ— R2ï¼š\", round(r2_score(y_test, y_pred_rf), 3))\n",
    "print(\"ğŸŒ² éšæœºæ£®æ— RMSEï¼š\", round(np.sqrt(mean_squared_error(y_test, y_pred_rf)), 3))\n",
    "\n",
    "# 7. ä¿å­˜æµ‹è¯•é›†é¢„æµ‹ä¸æ®‹å·®ï¼ˆç”¨äºåç»­åˆ†æï¼‰\n",
    "results = X_test.copy()\n",
    "results[\"true_obesity\"] = y_test.values\n",
    "results[\"pred_lr\"] = y_pred_lr\n",
    "results[\"pred_rf\"] = y_pred_rf\n",
    "results[\"resid_lr\"] = y_test.values - y_pred_lr\n",
    "results[\"resid_rf\"] = y_test.values - y_pred_rf\n",
    "\n",
    "# âœ… æ·»åŠ  MSOA_code åˆ—ï¼ˆä» index ä¸­è·å–ï¼‰\n",
    "results[\"MSOA_code\"] = X_test.index\n",
    "\n",
    "# 8. ä¿å­˜åˆ° CSV\n",
    "results.to_csv(\"Model_Results_with_Residuals.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64beb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#åŠ ä¸Šäº†å›¾åç»­å¯ä»¥çœ‹çœ‹æœ‰æ²¡æœ‰å¿…è¦\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# å‡†å¤‡æ•°æ®\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest'],\n",
    "    'R2': [r2_score(y_test, y_pred_lr), r2_score(y_test, y_pred_rf)],\n",
    "    'RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    ]\n",
    "})\n",
    "\n",
    "# RÂ²å¯¹æ¯”å›¾\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(metrics_df['Model'], metrics_df['R2'], color=['skyblue', 'forestgreen'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"RÂ² Comparison\")\n",
    "plt.ylabel(\"RÂ²\")\n",
    "plt.show()\n",
    "\n",
    "# RMSEå¯¹æ¯”å›¾\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(metrics_df['Model'], metrics_df['RMSE'], color=['skyblue', 'forestgreen'])\n",
    "plt.title(\"RMSE Comparison\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¾“å‡ºçº¿æ€§å›å½’ç³»æ•°\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Variable\": features,\n",
    "    \"Coefficient\": lr.coef_\n",
    "}).sort_values(\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "print(\"ğŸ“‹ çº¿æ€§å›å½’å˜é‡å½±å“ï¼ˆæŒ‰ç»å¯¹å€¼æ’åºï¼‰\")\n",
    "display(coef_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çœŸå® vs é¢„æµ‹å›¾\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_test, y_pred_lr, label=\"Linear Regression\", alpha=0.6)\n",
    "plt.scatter(y_test, y_pred_rf, label=\"Random Forest\", alpha=0.6)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', label=\"Ideal\")\n",
    "plt.xlabel(\"True Obesity Rate\")\n",
    "plt.ylabel(\"Predicted Obesity Rate\")\n",
    "plt.legend()\n",
    "plt.title(\"True vs Predicted Obesity Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#é˜¶æ®µå››shapæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc505efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# åˆå§‹åŒ– TreeExplainerï¼ˆé€‚ç”¨äºéšæœºæ£®æ—ï¼‰\n",
    "explainer = shap.Explainer(rf, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# 1. Summary Plotï¼ˆå…¨å±€å˜é‡é‡è¦æ€§ï¼‰\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯é€‰ï¼šå˜é‡é‡è¦æ€§æ¡å½¢å›¾ï¼ˆç®€æ´ç‰ˆï¼‰\n",
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯é€‰ï¼šForce Plotï¼ˆè§£é‡ŠæŸä¸€ä¸ªåœ°åŒºçš„é¢„æµ‹ï¼‰\n",
    "# Force plot for the first prediction\n",
    "shap.initjs()\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values.values[i],\n",
    "    X_test.iloc[i]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e003911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bce12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288aada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. è¯»å–åœ°å›¾å’Œæ¨¡å‹ç»“æœæ•°æ®\n",
    "gdf = gpd.read_file(\"MSOA_boundaries.geojson\")\n",
    "residuals = pd.read_csv(\"Model_Results_with_Residuals.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GeoDataFrame åˆ—åï¼š\")\n",
    "print(gdf.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef390c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"æ¨¡å‹ç»“æœè¡¨åˆ—åï¼š\")\n",
    "print(residuals.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æ”¹å\n",
    "gdf = gdf.rename(columns={\"MSOA21CD\": \"MSOA_code\"})\n",
    "\n",
    "# 2. ç±»å‹ä¸€è‡´ + å»ç©ºæ ¼\n",
    "gdf[\"MSOA_code\"] = gdf[\"MSOA_code\"].astype(str).str.strip()\n",
    "residuals[\"MSOA_code\"] = residuals[\"MSOA_code\"].astype(str).str.strip()\n",
    "\n",
    "# 3. åœ°å›¾ä¸­ä»…ä¿ç•™å«é¢„æµ‹ç»“æœçš„ MSOA åŒºåŸŸ\n",
    "gdf_subset = gdf[gdf[\"MSOA_code\"].isin(residuals[\"MSOA_code\"])].copy()\n",
    "\n",
    "# 4. åˆå¹¶åœ°å›¾ä¸é¢„æµ‹ç»“æœ\n",
    "gdf_merged = gdf_subset.merge(residuals, on=\"MSOA_code\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_merged[\"resid_rf\"].isnull().sum())\n",
    "print(gdf_merged[\"resid_rf\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d53e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm, LinearSegmentedColormap\n",
    "\n",
    "# è‡ªå®šä¹‰è‰²å¸¦ï¼šè“ â†’ ç° â†’ çº¢ï¼ˆä¸­é—´è‰²ä¸æ˜¯ç™½è‰²ï¼ï¼‰\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"custom_bwr\",\n",
    "    [\"#2166ac\", \"#d9d9d9\", \"#b2182b\"],  # è“ â†’ ç° â†’ çº¢\n",
    "    N=256\n",
    ")\n",
    "\n",
    "# è®¾å®šä¸­å€¼ä¸º 0ï¼Œå¯¹ç§°è‰²å¸¦èŒƒå›´\n",
    "norm = TwoSlopeNorm(vmin=-10, vcenter=0, vmax=10)\n",
    "\n",
    "# ç»˜å›¾\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "gdf_merged.plot(\n",
    "    column=\"resid_rf\",\n",
    "    cmap=custom_cmap,         # âœ… ä½¿ç”¨è‡ªå®šä¹‰è‰²å¸¦\n",
    "    linewidth=0.3,\n",
    "    edgecolor=\"grey\",\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    norm=norm,\n",
    "    missing_kwds={\"color\": \"lightgrey\", \"label\": \"æ— æ¨¡å‹æ•°æ®\"}\n",
    ")\n",
    "\n",
    "# å›¾æ ‡é¢˜ä¸ç¾åŒ–\n",
    "ax.set_title(\"ğŸ—ºï¸ éšæœºæ£®æ—æ¨¡å‹æ®‹å·®åœ°å›¾ï¼ˆLondon MSOAï¼‰\", fontsize=16, pad=12)\n",
    "ax.axis(\"off\")\n",
    "fig.get_axes()[1].set_ylabel(\"é¢„æµ‹æ®‹å·®ï¼ˆå®é™… - é¢„æµ‹ï¼‰\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae038f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"æ€» MSOA åŒºæ•°é‡ï¼ˆåœ°å›¾å­é›†ï¼‰ï¼š\", gdf_subset.shape[0])\n",
    "print(\"å«æ®‹å·®æ•°æ®çš„æ•°é‡ï¼š\", gdf_merged['resid_rf'].notna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e98fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_merged[\"resid_rf\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd738fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# 1. å‡†å¤‡å…¨ä½“æ•°æ®ï¼ˆä»ä¹‹å‰å®šä¹‰çš„å˜é‡ä¸­è·å–ï¼‰\n",
    "X_all = X.copy()  # å·²åŒ…å«æ‰€æœ‰ 935 ä¸ª MSOA\n",
    "y_all = y.copy()\n",
    "\n",
    "# 2. å¯¹å…¨ä½“æ•°æ®é¢„æµ‹\n",
    "y_pred_full = rf.predict(X_all)\n",
    "\n",
    "# 3. æ„å»ºåŒ…å«çœŸå®å€¼ã€é¢„æµ‹å€¼ã€æ®‹å·®çš„å®Œæ•´ DataFrame\n",
    "resid_full = pd.DataFrame({\n",
    "    \"MSOA_code\": X_all.index,\n",
    "    \"true_obesity\": y_all.values,\n",
    "    \"pred_rf\": y_pred_full,\n",
    "    \"resid_rf\": y_all.values - y_pred_full\n",
    "})\n",
    "\n",
    "# 4. è¯»å–åœ°å›¾æ•°æ®ï¼ˆå¦‚æœªè¯»å–ï¼‰\n",
    "import geopandas as gpd\n",
    "gdf = gpd.read_file(\"MSOA_boundaries.geojson\")\n",
    "\n",
    "# 5. æ‹¼æ¥ï¼šå…ˆç¡®ä¿ç¼–ç æ ¼å¼ä¸€è‡´\n",
    "gdf = gdf.rename(columns={\"MSOA21CD\": \"MSOA_code\"})\n",
    "gdf[\"MSOA_code\"] = gdf[\"MSOA_code\"].astype(str).str.strip()\n",
    "resid_full[\"MSOA_code\"] = resid_full[\"MSOA_code\"].astype(str).str.strip()\n",
    "\n",
    "# 6. åˆå¹¶åœ°å›¾ä¸é¢„æµ‹ç»“æœ\n",
    "gdf_full = gdf.merge(resid_full, on=\"MSOA_code\", how=\"left\")\n",
    "\n",
    "# 7. ç»˜å›¾ï¼ˆç¾è§‚ç‰ˆï¼‰\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-5, vcenter=0, vmax=5)\n",
    "\n",
    "gdf_full.plot(\n",
    "    column=\"resid_rf\",\n",
    "    cmap=\"RdYlBu_r\",\n",
    "    linewidth=0.1,\n",
    "    edgecolor=\"white\",\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    norm=norm,\n",
    "    missing_kwds={\"color\": \"lightgrey\", \"label\": \"æ— æ¨¡å‹æ•°æ®\"}\n",
    ")\n",
    "\n",
    "ax.set_title(\"ğŸ—ºï¸ å…¨ä¼¦æ•¦ MSOA æ®‹å·®åœ°å›¾ï¼ˆå®Œæ•´é¢„æµ‹ï¼‰\", fontsize=16, pad=12)\n",
    "ax.axis(\"off\")\n",
    "fig.get_axes()[1].set_ylabel(\"é¢„æµ‹æ®‹å·®ï¼ˆçœŸå® - é¢„æµ‹ï¼‰\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# âœ… åªä¿ç•™æœ‰é¢„æµ‹ç»“æœçš„ MSOAï¼ˆ935 ä¸ªä¼¦æ•¦åŒºåŸŸï¼‰\n",
    "gdf_london = gdf_full.dropna(subset=[\"resid_rf\"])\n",
    "\n",
    "# âœ… ç»˜å›¾\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=-5, vcenter=0, vmax=5)\n",
    "\n",
    "gdf_london.plot(\n",
    "    column=\"resid_rf\",\n",
    "    cmap=\"RdYlBu_r\",\n",
    "    linewidth=0.3,\n",
    "    edgecolor=\"white\",\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    norm=norm\n",
    ")\n",
    "\n",
    "ax.set_title(\"ğŸŒ ä¼¦æ•¦ MSOA æ®‹å·®åœ°å›¾ï¼ˆä»…å«æœ‰é¢„æµ‹ç»“æœåŒºåŸŸï¼‰\", fontsize=16, pad=12)\n",
    "ax.axis(\"off\")\n",
    "fig.get_axes()[1].set_ylabel(\"é¢„æµ‹æ®‹å·®ï¼ˆçœŸå® - é¢„æµ‹ï¼‰\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25912c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e7b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a9842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- K-Means èšç±»åˆ†æ ---\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ä½¿ç”¨åŒä¸€æ‰¹ç‰¹å¾è¿›è¡Œèšç±»åˆ†æ\n",
    "X_kmeans = merged_clean[features]\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_kmeans)\n",
    "\n",
    "# ä½¿ç”¨è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³ç°‡æ•°\n",
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, 10), wcss, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ä½¿ç”¨æœ€ä½³ k å€¼è¿›è¡Œèšç±»ï¼ˆå‡è®¾ä¸º3ï¼‰\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# æ·»åŠ èšç±»æ ‡ç­¾\n",
    "merged_clean['cluster'] = clusters\n",
    "\n",
    "# å¯è§†åŒ–èšç±»ç»“æœ\n",
    "sns.pairplot(merged_clean[features + ['cluster']], hue='cluster', palette='tab10')\n",
    "plt.suptitle(\"K-Means èšç±»ç»“æœ\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# --- SHAP åˆ†æï¼ˆè§£é‡Šéšæœºæ£®æ—æ¨¡å‹ï¼‰---\n",
    "import shap\n",
    "\n",
    "# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ä½¿ç”¨ TreeExplainer\n",
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# ç”Ÿæˆ SHAP æ€»ä½“é‡è¦æ€§å›¾\n",
    "shap.plots.beeswarm(shap_values)\n",
    "\n",
    "# ç”Ÿæˆå•ä¸ªæ ·æœ¬çš„ SHAP force plotï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a76c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- K-Means èšç±»åˆ†æ ---\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ä½¿ç”¨åŒä¸€æ‰¹ç‰¹å¾è¿›è¡Œèšç±»åˆ†æ\n",
    "X_kmeans = merged_clean[features]\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_kmeans)\n",
    "\n",
    "# ä½¿ç”¨è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³ç°‡æ•°\n",
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, 10), wcss, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ä½¿ç”¨æœ€ä½³ k å€¼è¿›è¡Œèšç±»ï¼ˆå‡è®¾ä¸º3ï¼‰\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# æ·»åŠ èšç±»æ ‡ç­¾\n",
    "merged_clean['cluster'] = clusters\n",
    "\n",
    "# å¯è§†åŒ–èšç±»ç»“æœ\n",
    "sns.pairplot(merged_clean[features + ['cluster']], hue='cluster', palette='tab10')\n",
    "plt.suptitle(\"K-Means èšç±»ç»“æœ\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# --- SHAP åˆ†æï¼ˆè§£é‡Šéšæœºæ£®æ—æ¨¡å‹ï¼‰---\n",
    "import shap\n",
    "\n",
    "# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ä½¿ç”¨ TreeExplainer\n",
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# ç”Ÿæˆ SHAP æ€»ä½“é‡è¦æ€§å›¾\n",
    "shap.plots.beeswarm(shap_values)\n",
    "\n",
    "# ç”Ÿæˆå•ä¸ªæ ·æœ¬çš„ SHAP force plotï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- K-Means èšç±»åˆ†æ ---\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ä½¿ç”¨åŒä¸€æ‰¹ç‰¹å¾è¿›è¡Œèšç±»åˆ†æ\n",
    "X_kmeans = merged_clean[features]\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_kmeans)\n",
    "\n",
    "# ä½¿ç”¨è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³ç°‡æ•°\n",
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, 10), wcss, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ä½¿ç”¨æœ€ä½³ k å€¼è¿›è¡Œèšç±»ï¼ˆå‡è®¾ä¸º3ï¼‰\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# æ·»åŠ èšç±»æ ‡ç­¾\n",
    "merged_clean['cluster'] = clusters\n",
    "\n",
    "# å¯è§†åŒ–èšç±»ç»“æœ\n",
    "sns.pairplot(merged_clean[features + ['cluster']], hue='cluster', palette='tab10')\n",
    "plt.suptitle(\"K-Means èšç±»ç»“æœ\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# --- SHAP åˆ†æï¼ˆè§£é‡Šéšæœºæ£®æ—æ¨¡å‹ï¼‰---\n",
    "import shap\n",
    "\n",
    "# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ä½¿ç”¨ TreeExplainer\n",
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# ç”Ÿæˆ SHAP æ€»ä½“é‡è¦æ€§å›¾\n",
    "shap.plots.beeswarm(shap_values)\n",
    "\n",
    "# ç”Ÿæˆå•ä¸ªæ ·æœ¬çš„ SHAP force plotï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
